{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0fvK3Rgac3X"
   },
   "source": [
    "# PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jvt_q5jKL2y"
   },
   "source": [
    "## Paper Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS5vzHkTbVkn"
   },
   "source": [
    "### Prior Reseach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LiDAR를 통해서 얻어지는 Point Cloud를 2D 변환을 통해 3D representation을 얻는 방법은 **front-view** 또는 **bird's-eye-view** 변환이 대표적     \n",
    "둘은 모두 quantization, projection을 통해서 computationally expensive한 3D operation을 회피한다는 점에서 좋은 선택이었음  \n",
    "그러나 depth-map을 통해 front-view 변환은 scale, range information을 잃지 않는 BEV보다 empirical하게 performance가 좋지 못했음  \n",
    "\n",
    "따라서 BEV 변환 후에 좋은 representation을 얻는 것이 중요한데 지금까지의 approach는 **Cartesian coordinate**로 quantization이 이루어짐  \n",
    "→ 그러나 LiDAR scanner와 가까울수록 많은 point가 scan되는 특성에 따라 Cartesian map은 label과 일치하는 quantization이 어려움  \n",
    "\n",
    "∴ 조금 더 좋은 quantization/catching representation을 위해서 **polar coordinate** 상에서 convolution을 수행하는 **PolarNet**을 제안    \n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"898\" alt=\"1\" src=\"https://user-images.githubusercontent.com/86907286/204104229-eb74197f-e886-403b-9d4c-682d40b7fe9c.png\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polar Bird's-Eye-View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D representation에서 BEV 변환은 많은 발전이 이루어진 natural image에 대한 CNN을 적용할 수 있는 변환으로서 많이 활용되었음  \n",
    "단순한 top-down projection을 넘어서 height, reflection 등 많은 것을 동시에 encode하는 접근이 있지만 여전히 **Cartesian coordinate**를 사용하고 있음  \n",
    "이는 이후 convolution을 위해 quantization을 진행하는 과정에서 **censor가 위치하는 중앙 근처의 grid에 많은 point가 밀집**하는 현상으로 이어짐  \n",
    "→ computational power를 낭비할 뿐만 아니라 **서로 다른 label을 갖는 point가 섞여** representation을 catch하는데 어려움이 발생할 수 있음 \n",
    "\n",
    "∴ censor가 위치한 center를 중심으로 LiDAR point가 얻어진다는 점에서 **polar coordinate**를 통한 quantization이 조금 더 자연스러운 접근법이라고 할 수 있음\n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"436\" alt=\"2\" src=\"https://user-images.githubusercontent.com/86907286/204104235-5cb991a0-76af-4e19-98a2-554fe59ac32c.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Polar Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polar coordinate를 기준으로 quantization을 진행한다고 해도 바로 hand-crafted feature로 변환하는 것은 비효율적이라고 할 수 있음  \n",
    "→ **PointNet**처럼 polar grid(또는 Cartesian grid)를 기준으로 일정 grid 내부에서 shared weight MLP $h(\\cdot)$을 통해 representation을 catch하여 사용\n",
    "\n",
    "$$ \\text{fea}_{i, j} = \\max (\\{h(p) | w_i < p_x < w_{i+1},  l_j < p_y < l_{j+1}\\}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 얻어진 point representation을 polar grid로 나누어서 convolution을 통해 prediction을 위한 grid representation을 얻을 필요가 있음  \n",
    "이때 polar grid 상에서의 2d convolution을 진행하기 위해서는 **하나의 polar grid cell에서 인접한 모든 cell**을 convolution 시에 참조할 필요가 있음  \n",
    "→ polar grid 상에서 상하좌우로 연결된 cell을 참조하는(≈ circular convolution) **ring convolution**으로 2d convolution을 대체하여 CNN Architecture 구성\n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"436\" alt=\"3\" src=\"https://user-images.githubusercontent.com/86907286/204104238-bd117544-e1a7-4d55-b154-07547328b58c.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Projection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 이렇게 polar BEV를 기존의 2D spherical projection, Cartesian BEV와 서로 다른 backbone을 사용하여 비교한 결과는 다음과 같음\n",
    "\n",
    "1. spherical projection은 quantization error와 distance 정보의 상실로 인해 인접한 same label point를 다르게 classification하는 경향이 관찰됨    \n",
    "2. BEV 방식은 공통적으로 distance가 멀어질 경우 sample이 적어져 mIoU가 비슷해졌지만 인접한 경우에는 Cartesian BEV의 mIoU가 더 낮았음   \n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"436\" alt=\"4\" src=\"https://user-images.githubusercontent.com/86907286/204104239-0180ff3e-c769-4686-9248-9d9ed2c353c1.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxPFMMWQKOEY"
   },
   "source": [
    "## Implementation Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Dataset to Polar Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spherical_dataset(data.Dataset):\n",
    "  def __init__(self, in_dataset, grid_size, rotate_aug = False, flip_aug = False, ignore_label = 255, return_test = False,\n",
    "               fixed_volume_space= False, max_volume_space = [50,np.pi,1.5], min_volume_space = [3,-np.pi,-3]):\n",
    "        'Initialization'\n",
    "        self.point_cloud_dataset = in_dataset\n",
    "        self.grid_size = np.asarray(grid_size)\n",
    "        self.rotate_aug = rotate_aug\n",
    "        self.flip_aug = flip_aug\n",
    "        self.ignore_label = ignore_label\n",
    "        self.return_test = return_test\n",
    "        self.fixed_volume_space = fixed_volume_space\n",
    "        self.max_volume_space = max_volume_space\n",
    "        self.min_volume_space = min_volume_space\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.point_cloud_dataset)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        data = self.point_cloud_dataset[index]\n",
    "        if len(data) == 2:\n",
    "            xyz,labels = data\n",
    "        elif len(data) == 3:\n",
    "            xyz,labels,sig = data\n",
    "            if len(sig.shape) == 2: sig = np.squeeze(sig)\n",
    "        else: raise Exception('Return invalid data tuple')\n",
    "        \n",
    "        # random data augmentation by rotation\n",
    "        if self.rotate_aug:\n",
    "            rotate_rad = np.deg2rad(np.random.random()*360)\n",
    "            c, s = np.cos(rotate_rad), np.sin(rotate_rad)\n",
    "            j = np.matrix([[c, s], [-s, c]])\n",
    "            xyz[:,:2] = np.dot( xyz[:,:2],j)\n",
    "\n",
    "        # random data augmentation by flip x , y or x+y\n",
    "        if self.flip_aug:\n",
    "            flip_type = np.random.choice(4,1)\n",
    "            if flip_type==1:\n",
    "                xyz[:,0] = -xyz[:,0]\n",
    "            elif flip_type==2:\n",
    "                xyz[:,1] = -xyz[:,1]\n",
    "            elif flip_type==3:\n",
    "                xyz[:,:2] = -xyz[:,:2]\n",
    "\n",
    "        # convert coordinate into polar coordinates\n",
    "        xyz_pol = cart2polar(xyz)\n",
    "        \n",
    "        max_bound_r = np.percentile(xyz_pol[:,0],100,axis = 0)\n",
    "        min_bound_r = np.percentile(xyz_pol[:,0],0,axis = 0)\n",
    "        max_bound = np.max(xyz_pol[:,1:],axis = 0)\n",
    "        min_bound = np.min(xyz_pol[:,1:],axis = 0)\n",
    "        max_bound = np.concatenate(([max_bound_r],max_bound))\n",
    "        min_bound = np.concatenate(([min_bound_r],min_bound))\n",
    "        if self.fixed_volume_space:\n",
    "            max_bound = np.asarray(self.max_volume_space)\n",
    "            min_bound = np.asarray(self.min_volume_space)\n",
    "\n",
    "        # get grid index\n",
    "        crop_range = max_bound - min_bound\n",
    "        cur_grid_size = self.grid_size\n",
    "        intervals = crop_range/(cur_grid_size-1)\n",
    "\n",
    "        if (intervals==0).any(): print(\"Zero interval!\")\n",
    "        grid_ind = (np.floor((np.clip(xyz_pol,min_bound,max_bound)-min_bound)/intervals)).astype(np.int)\n",
    "\n",
    "        # process voxel position\n",
    "        voxel_position = np.zeros(self.grid_size,dtype = np.float32)\n",
    "        dim_array = np.ones(len(self.grid_size)+1,int)\n",
    "        dim_array[0] = -1 \n",
    "        voxel_position = np.indices(self.grid_size)*intervals.reshape(dim_array) + min_bound.reshape(dim_array)\n",
    "        # voxel_position = polar2cat(voxel_position)\n",
    "        \n",
    "        # process labels\n",
    "        processed_label = np.ones(self.grid_size,dtype = np.uint8)*self.ignore_label\n",
    "        label_voxel_pair = np.concatenate([grid_ind,labels],axis = 1)\n",
    "        label_voxel_pair = label_voxel_pair[np.lexsort((grid_ind[:,0],grid_ind[:,1],grid_ind[:,2])),:]\n",
    "        processed_label = nb_process_label(np.copy(processed_label),label_voxel_pair)\n",
    "        # data_tuple = (voxel_position,processed_label)\n",
    "\n",
    "        # prepare visiblity feature\n",
    "        # find max distance index in each angle,height pair\n",
    "        valid_label = np.zeros_like(processed_label,dtype=bool)\n",
    "        valid_label[grid_ind[:,0],grid_ind[:,1],grid_ind[:,2]] = True\n",
    "        valid_label = valid_label[::-1]\n",
    "        max_distance_index = np.argmax(valid_label,axis=0)\n",
    "        max_distance = max_bound[0]-intervals[0]*(max_distance_index)\n",
    "        distance_feature = np.expand_dims(max_distance, axis=2)-np.transpose(voxel_position[0],(1,2,0))\n",
    "        distance_feature = np.transpose(distance_feature,(1,2,0))\n",
    "        # convert to boolean feature\n",
    "        distance_feature = (distance_feature>0)*-1.\n",
    "        distance_feature[grid_ind[:,2],grid_ind[:,0],grid_ind[:,1]]=1.\n",
    "\n",
    "        data_tuple = (distance_feature,processed_label)\n",
    "\n",
    "        # center data on each voxel for PTnet\n",
    "        voxel_centers = (grid_ind.astype(np.float32) + 0.5)*intervals + min_bound\n",
    "        return_xyz = xyz_pol - voxel_centers\n",
    "        return_xyz = np.concatenate((return_xyz,xyz_pol,xyz[:,:2]),axis = 1)\n",
    "\n",
    "        if len(data) == 2:\n",
    "            return_fea = return_xyz\n",
    "        elif len(data) == 3:\n",
    "            return_fea = np.concatenate((return_xyz,sig[...,np.newaxis]),axis = 1)\n",
    "        \n",
    "        if self.return_test:\n",
    "            data_tuple += (grid_ind,labels,return_fea,index)\n",
    "        else:\n",
    "            data_tuple += (grid_ind,labels,return_fea)\n",
    "        return data_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ring Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv_circular(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch,group_conv,dilation=1):\n",
    "        super(double_conv_circular, self).__init__()\n",
    "        if group_conv:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=(1,0),groups = min(out_ch,in_ch)),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(out_ch, out_ch, 3, padding=(1,0),groups = out_ch),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=(1,0)),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(out_ch, out_ch, 3, padding=(1,0)),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #add circular padding\n",
    "        x = F.pad(x,(1,1,0,0),mode = 'circular')\n",
    "        x = self.conv1(x)\n",
    "        x = F.pad(x,(1,1,0,0),mode = 'circular')\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ak0Dn-LURm2"
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahcpUlB9UUpB"
   },
   "source": [
    "- https://arxiv.org/abs/2003.14032\n",
    "- https://github.com/edwardzhou130/PolarSeg"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOy6sMktL3Wiz8Wfsn1WpYv",
   "collapsed_sections": [
    "uxPFMMWQKOEY",
    "-w2YtibfT8Zy",
    "5g9CBFXgUuNR",
    "7hkeM1CRU3W0"
   ],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
